{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import base64\n",
    "# def openai_image_prompt(api_key, image_path, prompt, model=\"gpt-4-vision-preview\"):\n",
    "#     with open(image_path, \"rb\") as img_file:\n",
    "#         image_bytes = img_file.read()\n",
    "#     base64_image =base64.b64encode(image_bytes).decode('utf-8')\n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {api_key}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "#     data = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\"type\": \"text\", \"text\": prompt},\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\n",
    "#                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ],\n",
    "#         \"max_tokens\": 512\n",
    "#     }\n",
    "#     response = openai.ChatCompletion.create(**data)\n",
    "#     return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc110a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca4272",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai._utils' has no attribute 'to_base64'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mopenai_image_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnecklace.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDescribe the content of this image in detail.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mopenai_image_prompt\u001b[39m\u001b[34m(api_key, image_path, prompt, model)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[32m      5\u001b[39m     image_bytes = img_file.read()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m base64_image = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_base64\u001b[49m(image_bytes)\n\u001b[32m      7\u001b[39m headers = {\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m }\n\u001b[32m     11\u001b[39m data = {\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m\n\u001b[32m     28\u001b[39m }\n",
      "\u001b[31mAttributeError\u001b[39m: module 'openai._utils' has no attribute 'to_base64'"
     ]
    }
   ],
   "source": [
    "# response = openai_image_prompt(\n",
    "#     api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "#     image_path=\"necklace.png\",\n",
    "#     prompt=\"Describe the content of this image in detail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e644937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"))\n",
    "\n",
    "prompt = \"\"\"\n",
    "Use the provided image of the necklace and create a photorealistic image of a modern Indian model wearing this exact necklace. \n",
    "Ensure the necklace remains the same size and appearance as in the original image. \n",
    "The model should be posed naturally, with the necklace clearly visible, and the background should be simple and neutral.\n",
    "Do not change the necklace's design, size, or color.\n",
    "\"\"\"\n",
    "\n",
    "result = client.images.edit(\n",
    "    model=\"gpt-image-1\",\n",
    "    image=[\n",
    "        open(r\"jewellery images\\necklace\\necklace.png\", \"rb\"),\n",
    "    ],\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "image_base64 = result.data[0].b64_json\n",
    "image_bytes = base64.b64decode(image_base64)\n",
    "\n",
    "# Save the image to a file\n",
    "with open(\"gift-basket.png\", \"wb\") as f:\n",
    "    f.write(image_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "image = PIL.Image.open('/path/to/image.png')\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "text_input = ('Hi, This is a picture of me.'\n",
    "            'Can you add a llama next to me?',)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "    contents=[text_input, image],\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['TEXT', 'IMAGE']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO((part.inline_data.data)))\n",
    "    image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
